{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport shutil\n\nimport torch\nfrom torchvision.utils import make_grid\nfrom torchvision import transforms\nimport torchvision.transforms.functional as TF\nfrom torch import nn, optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.utils.data import DataLoader, Dataset\nfrom huggingface_hub import hf_hub_download","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-25T11:24:41.575999Z","iopub.execute_input":"2022-04-25T11:24:41.576602Z","iopub.status.idle":"2022-04-25T11:24:47.243355Z","shell.execute_reply.started":"2022-04-25T11:24:41.576562Z","shell.execute_reply":"2022-04-25T11:24:47.242271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Upsample(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1, dropout=True):\n        super(Upsample, self).__init__()\n        self.dropout = dropout\n        self.block = nn.Sequential(\n            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=nn.InstanceNorm2d),\n            nn.InstanceNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n        self.dropout_layer = nn.Dropout2d(0.5)\n\n    def forward(self, x, shortcut=None):\n        x = self.block(x)\n        if self.dropout:\n            x = self.dropout_layer(x)\n\n        if shortcut is not None:\n            x = torch.cat([x, shortcut], dim=1)\n\n        return x\n\n\nclass Downsample(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1, apply_instancenorm=True):\n        super(Downsample, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=nn.InstanceNorm2d)\n        self.norm = nn.InstanceNorm2d(out_channels)\n        self.relu = nn.LeakyReLU(0.2, inplace=True)\n        self.apply_norm = apply_instancenorm\n\n    def forward(self, x):\n        x = self.conv(x)\n        if self.apply_norm:\n            x = self.norm(x)\n        x = self.relu(x)\n\n        return x\n\n\nclass CycleGAN_Unet_Generator(nn.Module):\n    def __init__(self, filter=64):\n        super(CycleGAN_Unet_Generator, self).__init__()\n        self.downsamples = nn.ModuleList([\n            Downsample(3, filter, kernel_size=4, apply_instancenorm=False),  # (b, filter, 128, 128)\n            Downsample(filter, filter * 2),  # (b, filter * 2, 64, 64)\n            Downsample(filter * 2, filter * 4),  # (b, filter * 4, 32, 32)\n            Downsample(filter * 4, filter * 8),  # (b, filter * 8, 16, 16)\n            Downsample(filter * 8, filter * 8), # (b, filter * 8, 8, 8)\n            Downsample(filter * 8, filter * 8), # (b, filter * 8, 4, 4)\n            Downsample(filter * 8, filter * 8), # (b, filter * 8, 2, 2)\n        ])\n\n        self.upsamples = nn.ModuleList([\n            Upsample(filter * 8, filter * 8),\n            Upsample(filter * 16, filter * 8),\n            Upsample(filter * 16, filter * 8),\n            Upsample(filter * 16, filter * 4, dropout=False),\n            Upsample(filter * 8, filter * 2, dropout=False),\n            Upsample(filter * 4, filter, dropout=False)\n        ])\n\n        self.last = nn.Sequential(\n            nn.ConvTranspose2d(filter * 2, 3, kernel_size=4, stride=2, padding=1),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        skips = []\n        for l in self.downsamples:\n            x = l(x)\n            skips.append(x)\n\n        skips = reversed(skips[:-1])\n        for l, s in zip(self.upsamples, skips):\n            x = l(x, s)\n\n        out = self.last(x)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-04-25T11:24:51.018975Z","iopub.execute_input":"2022-04-25T11:24:51.019271Z","iopub.status.idle":"2022-04-25T11:24:51.044905Z","shell.execute_reply.started":"2022-04-25T11:24:51.019238Z","shell.execute_reply":"2022-04-25T11:24:51.043846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = hf_hub_download('huggan/NeonGAN', 'model.bin')","metadata":{"execution":{"iopub.status.busy":"2022-04-25T11:25:51.151409Z","iopub.execute_input":"2022-04-25T11:25:51.151756Z","iopub.status.idle":"2022-04-25T11:25:55.791026Z","shell.execute_reply.started":"2022-04-25T11:25:51.151723Z","shell.execute_reply":"2022-04-25T11:25:55.789784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_gen_n = torch.load(path, map_location=torch.device('cpu'))","metadata":{"execution":{"iopub.status.busy":"2022-04-25T11:26:11.88273Z","iopub.execute_input":"2022-04-25T11:26:11.883059Z","iopub.status.idle":"2022-04-25T11:26:12.029787Z","shell.execute_reply.started":"2022-04-25T11:26:11.883013Z","shell.execute_reply":"2022-04-25T11:26:12.028944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageTransform:\n    def __init__(self, img_size=256):\n        self.transform = {\n            'train': transforms.Compose([\n                transforms.Resize((img_size, img_size)),\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomVerticalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.5], std=[0.5])\n            ]),\n            'test': transforms.Compose([\n                transforms.Resize((img_size, img_size)),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.5], std=[0.5])\n            ])}\n\n    def __call__(self, img, phase='train'):\n        img = self.transform[phase](img)\n\n        return img","metadata":{"execution":{"iopub.status.busy":"2022-04-25T11:10:41.002032Z","iopub.execute_input":"2022-04-25T11:10:41.002356Z","iopub.status.idle":"2022-04-25T11:10:41.009741Z","shell.execute_reply.started":"2022-04-25T11:10:41.002302Z","shell.execute_reply":"2022-04-25T11:10:41.008863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport numpy as np\n\nphoto_img_paths = glob.glob('../input/photos/*.jpg')\ntransform = ImageTransform(img_size=256)\n    \n#print(photo_img_paths[0])\nimages = []\nfor path in photo_img_paths[0:10]:\n    photo_id = path.split('/')[-1]\n    img = transform(Image.open(path), phase='test')\n\n    gen_img = model_gen_n(img.unsqueeze(0))[0]\n\n    # Reverse Normalization\n    gen_img = gen_img * 0.5 + 0.5\n    gen_img = gen_img * 255\n    gen_img = gen_img.detach().cpu().numpy().astype(np.uint8)\n\n    gen_img = np.transpose(gen_img, [1,2,0])\n\n    gen_img = Image.fromarray(gen_img)\n    \n    images.append(gen_img)\n    print(path,'done')","metadata":{"execution":{"iopub.status.busy":"2022-04-25T11:11:38.647806Z","iopub.execute_input":"2022-04-25T11:11:38.648251Z","iopub.status.idle":"2022-04-25T11:11:40.443807Z","shell.execute_reply.started":"2022-04-25T11:11:38.648216Z","shell.execute_reply":"2022-04-25T11:11:40.442911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(images[2])","metadata":{"execution":{"iopub.status.busy":"2022-04-25T11:13:37.732994Z","iopub.execute_input":"2022-04-25T11:13:37.733297Z","iopub.status.idle":"2022-04-25T11:13:37.762095Z","shell.execute_reply.started":"2022-04-25T11:13:37.733266Z","shell.execute_reply":"2022-04-25T11:13:37.761171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = ImageTransform(img_size=256)\nimg = transform(Image.open('../input/photos/4a06596662.jpg'), phase='test')\n\ngen_img = model_gen_n(img.unsqueeze(0))[0]\n\n# Reverse Normalization\ngen_img = gen_img * 0.5 + 0.5\ngen_img = gen_img * 255\ngen_img = gen_img.detach().cpu().numpy().astype(np.uint8)\n\ngen_img = np.transpose(gen_img, [1,2,0])\n\ngen_img = Image.fromarray(gen_img)\n\n\ndisplay(gen_img)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T11:30:10.533402Z","iopub.execute_input":"2022-04-25T11:30:10.534404Z","iopub.status.idle":"2022-04-25T11:30:10.748681Z","shell.execute_reply.started":"2022-04-25T11:30:10.53434Z","shell.execute_reply":"2022-04-25T11:30:10.747736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}